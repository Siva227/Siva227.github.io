<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.340">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Siva Sankar E.V.P">
<meta name="dcterms.date" content="2023-12-23">
<meta name="description" content="Exploring the applicability of VAEs in Semi-Supervised Learning">

<title>Siva Sankar E.V.P - Variational Autoencoders in Semi-Supervised learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../images/favicon.ico" rel="icon">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
<meta name="twitter:title" content="Siva Sankar E.V.P - Variational Autoencoders in Semi-Supervised learning">
<meta name="twitter:description" content="Exploring the applicability of VAEs in Semi-Supervised Learning">
<meta name="twitter:image" content="https://Siva227.github.io/a-late-run-blog/posts/vaes-and-mixture-models/figures/assumptions.png">
<meta name="twitter:creator" content="@Siva_emany">
<meta name="twitter:image-height" content="612">
<meta name="twitter:image-width" content="1419">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Siva Sankar E.V.P</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html" rel="" target="">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../projects.qmd" rel="" target="">
 <span class="menu-text">Projects</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../blog.html" rel="" target="">
 <span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../resume.html" rel="" target="">
 <span class="menu-text">Resume</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/Siva227" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/Siva_emany" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/siva-sankar-evp/" rel="" target=""><i class="bi bi-linkedin" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#motivating-problem" id="toc-motivating-problem" class="nav-link active" data-scroll-target="#motivating-problem"><span class="header-section-number">1</span> Motivating Problem</a>
  <ul class="collapse">
  <li><a href="#what-is-semi-supervised-learning" id="toc-what-is-semi-supervised-learning" class="nav-link" data-scroll-target="#what-is-semi-supervised-learning"><span class="header-section-number">1.1</span> What is Semi-Supervised Learning?</a></li>
  </ul></li>
  <li><a href="#variational-autoencodersvae" id="toc-variational-autoencodersvae" class="nav-link" data-scroll-target="#variational-autoencodersvae"><span class="header-section-number">2</span> Variational Autoencoders(VAE)</a>
  <ul class="collapse">
  <li><a href="#how-it-works" id="toc-how-it-works" class="nav-link" data-scroll-target="#how-it-works"><span class="header-section-number">2.1</span> How it works?</a></li>
  <li><a href="#the-math" id="toc-the-math" class="nav-link" data-scroll-target="#the-math"><span class="header-section-number">2.2</span> The Math</a></li>
  <li><a href="#beta-vaebeta-vae" id="toc-beta-vaebeta-vae" class="nav-link" data-scroll-target="#beta-vaebeta-vae"><span class="header-section-number">2.3</span> Beta-VAE(<span class="math inline">\(\beta\)</span>-VAE)</a></li>
  <li><a href="#implementation" id="toc-implementation" class="nav-link" data-scroll-target="#implementation"><span class="header-section-number">2.4</span> Implementation</a></li>
  <li><a href="#results" id="toc-results" class="nav-link" data-scroll-target="#results"><span class="header-section-number">2.5</span> Results</a></li>
  </ul></li>
  <li><a href="#semi-supervised-vaess-vae" id="toc-semi-supervised-vaess-vae" class="nav-link" data-scroll-target="#semi-supervised-vaess-vae"><span class="header-section-number">3</span> Semi-supervised VAE(SS-VAE)</a>
  <ul class="collapse">
  <li><a href="#latent-feature-discriminative-model---m1" id="toc-latent-feature-discriminative-model---m1" class="nav-link" data-scroll-target="#latent-feature-discriminative-model---m1"><span class="header-section-number">3.1</span> Latent feature discriminative model - M1</a></li>
  <li><a href="#generative-semi-supervised-model---m2" id="toc-generative-semi-supervised-model---m2" class="nav-link" data-scroll-target="#generative-semi-supervised-model---m2"><span class="header-section-number">3.2</span> Generative semi-supervised model - M2</a></li>
  <li><a href="#stacked-generative-semi-supervised-model---m1m2" id="toc-stacked-generative-semi-supervised-model---m1m2" class="nav-link" data-scroll-target="#stacked-generative-semi-supervised-model---m1m2"><span class="header-section-number">3.3</span> Stacked generative semi-supervised model - M1+M2</a></li>
  </ul></li>
  <li><a href="#infinite-vae" id="toc-infinite-vae" class="nav-link" data-scroll-target="#infinite-vae"><span class="header-section-number">4</span> Infinite VAE</a>
  <ul class="collapse">
  <li><a href="#mixture-models" id="toc-mixture-models" class="nav-link" data-scroll-target="#mixture-models"><span class="header-section-number">4.1</span> Mixture models</a></li>
  <li><a href="#dirichlet-process-mixture-models" id="toc-dirichlet-process-mixture-models" class="nav-link" data-scroll-target="#dirichlet-process-mixture-models"><span class="header-section-number">4.2</span> Dirichlet Process Mixture Models</a></li>
  </ul></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references"><span class="header-section-number">5</span> References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Variational Autoencoders in Semi-Supervised learning</h1>
  <div class="quarto-categories">
    <div class="quarto-category">ai</div>
    <div class="quarto-category">paper_review</div>
    <div class="quarto-category">exploration</div>
  </div>
  </div>

<div>
  <div class="description">
    Exploring the applicability of VAEs in Semi-Supervised Learning
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Siva Sankar E.V.P </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">December 23, 2023</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<section id="motivating-problem" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="motivating-problem"><span class="header-section-number">1</span> Motivating Problem</h2>
<p>The biggest hurdle an AI practitioner often faces is the lack of well labeled and annotated datasets for their specific task. The availability of a labels is the precursor to applying supervised learning techniques. This often requires a large human effort spent on annotation to make dataset usable and consumable by supervised learning models. However, by leveraging techniques like unsupervised and semi-supervised learning, practiotiners can help bring down this effort.</p>
<section id="what-is-semi-supervised-learning" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="what-is-semi-supervised-learning"><span class="header-section-number">1.1</span> What is Semi-Supervised Learning?</h3>
<p>Semi-supervised learning considers the problem of classification when only a small subset of the observations have corresponding class labels. It sits between supervised and unsupervised learning techniques. By annotating a manageable subset of data and utilizing semi-supervised learning techniques we can take advantage of the full dataset. In this article, I focus on semi-supervised classification techniques. In order to leverage these techniques, certain assumptions are made.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/assumptions.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Assumptions of Semi-Supervised Learning<span class="citation" data-cites="van2020survey">(<a href="#ref-van2020survey" role="doc-biblioref">Van Engelen and Hoos 2020</a>)</span></figcaption>
</figure>
</div>
<p><strong>Smoothness Assumption</strong></p>
<p>This assumption states that if two points are close together in the input space, their labels are the same.</p>
<p><strong>Low Density Assumption</strong></p>
<p>This assumption implies that the decision boundary should pass through a low-density area of the input-space.</p>
<p><strong>Manifold Assumption</strong></p>
<p>The manifold assumption in semi-supervised learning states that</p>
<ol type="1">
<li>the input space is composed of multiple lower-dimensional manifolds on which all data points lie and</li>
<li>data points lying on the same manifold have the same label.</li>
</ol>
<p>A manifold here refers to a lower dimensional representation of the input shapes. By learning informative manifolds, we can learn the labels of different data points.</p>
</section>
</section>
<section id="variational-autoencodersvae" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="variational-autoencodersvae"><span class="header-section-number">2</span> Variational Autoencoders(VAE)</h2>
<p>In the previous section, we spoke about some of the assumptions that we make when applying semi-supervised learning techniques. The manifold assumption is of particular interest here as by learning an informative lower dimensional representation of the input space, we can create supervised models by leveraing some or no labels. This is where a deep generative models like VAE and GAN(Generative Adversarial networks) can be utilized.</p>
<p>Generative models allow us to learn and approximate any kind of data distribution by just using the input data in an unsupervised way. Deep Generative models leverage neural network architectures to learn complex representation from high dimensional data like images, audio etc. In this exploration, we focus on Variational Autoencoders.</p>
<section id="how-it-works" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="how-it-works"><span class="header-section-number">2.1</span> How it works?</h3>
<p>Variational Autoencoders<span class="citation" data-cites="kingma2014stochastic">(<a href="#ref-kingma2014stochastic" role="doc-biblioref">Diederik P. Kingma and Welling 2014</a>)</span> are based on Autoencoders. Autoencoders are neural networks that attempt to predict their own inputs. It’s a self-supervised learning technique as labels are the input itself. It compresses the original feature space automatically by learning from examples. The network is divided into two components, an Encoder, which compresses the feature space and a Decoder which de-compresses the encoded feature space. The objective is to minimize the reconstruction loss. While it can’t be generalized beyond the data it is trained on, it has applications such as dimensionality reduction and de-noising.</p>
<div id="fig-vae" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="figures/vae_pgm.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;1: Graphical Model of VAE<span class="citation" data-cites="9941371">(<a href="#ref-9941371" role="doc-biblioref">Yang et al. 2022</a>)</span></figcaption>
</figure>
</div>
<p>Autoencoders learn a one-to-one representation of the data and this is the reason why they don’t generalize well and can’t generate new observations. VAEs extend the capability of autoencoders by learning a model which can generate complex data distributions from very simple latent variable distributions.</p>
</section>
<section id="the-math" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="the-math"><span class="header-section-number">2.2</span> The Math</h3>
<p>Given the graphical representation in <a href="#fig-vae">Figure&nbsp;1</a>, let us define the joint distribution <span class="math inline">\(p(x,z) = p(z)p(x|z)\)</span>. <span class="math inline">\(p(z)\)</span> is the prior distribution of the latent variable. We have the Encoder which approximates the true posterior <span class="math inline">\(p(z|x)\)</span> with <span class="math inline">\(q(z|x)\)</span> and the Decoder which parametrizes the likelihood <span class="math inline">\(p(x|z)\)</span>.</p>
<p><span class="math display">\[\begin{align*}
p(x,z) &amp;= p(z)p(x|z) \\
p(z) &amp;= \mathcal{N}(z|\mathbf{0},I)\\
p_{\theta}(x|z) &amp;= f(x;z,\theta)
\end{align*}\]</span></p>
<p>The function <span class="math inline">\(f(x;z,\theta)\)</span> is suitable likelihood function parametrized by a non-linear transformation of the latent variables. The parameters we learn here are <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> of the latent variable as a function of the encoder weights and input samples.</p>
<p><span class="math display">\[q_{\phi}(z|x) = \mathcal{N}(z|\mu_{\phi}(x), \sigma^2_{\phi}(x))\]</span></p>
<p><span class="math inline">\(\theta\)</span> and <span class="math inline">\(\phi\)</span> are neural network parameters which are not included in the bayesian analysis. The goal is to find good values of <span class="math inline">\(\theta\)</span> and <span class="math inline">\(\phi\)</span> such that <span class="math inline">\(q_{\phi}(z|x)\)</span> provides a good approximation of the true posterior and such that log probability of the observed value <span class="math inline">\(log(p(x))\)</span> is maximized. Hence, the ELBO of the model is the lower bound on <span class="math inline">\(log(p(x))\)</span>. This is given by</p>
<p><span class="math display">\[\begin{equation} \label{eq1}
ELBO(x) \equiv \int dz\ q(z|x)log\ p(x|z) + \int dz\ q(z|x)log\frac{q(z|x)}{p(z)}
\end{equation}\]</span></p>
<p>The first term here is the reconstruction loss which captures the likelihood of getting the original observation <span class="math inline">\(x\)</span> back after we encode it to <span class="math inline">\(z\)</span> and decode it. The second term is the KL Divergence term. Kullback-Leibler divergence is a particular (non-negative) measure of ‘closeness’ between two distributions. In this case the two distributions are <span class="math inline">\(p(z)\)</span> and the encoder <span class="math inline">\(q(z|x)\)</span>. If the encoder is generating samples of <span class="math inline">\(z\)</span> that are too unlikely given the prior, it is penalized. The encoder will learn a distribution where it differs from the prior when the cost of doing so is outweighed by the advantage of the reconstruction term.</p>
</section>
<section id="beta-vaebeta-vae" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="beta-vaebeta-vae"><span class="header-section-number">2.3</span> Beta-VAE(<span class="math inline">\(\beta\)</span>-VAE)</h3>
<p><span class="math inline">\(\beta\)</span>-VAE<span class="citation" data-cites="higgins2017beta">(<a href="#ref-higgins2017beta" role="doc-biblioref">Higgins et al. 2017</a>)</span> is an extension of VAE where a regularization coefficient <span class="math inline">\(\beta\)</span> is applied to the KL-Divergence term in the variational objective equation. Varying <span class="math inline">\(\beta\)</span> changes the degree of applied pressure on the latent variable. <span class="math inline">\(\beta=1\)</span> corresponds to the VAE equation described above. Setting <span class="math inline">\(\beta&gt;1\)</span> should help <span class="math inline">\(z\)</span> learn a more efficient representation of <span class="math inline">\(x\)</span> by putting tighter constraints on it. In the tensorflow-probability implementation, this weight is baked into the Kullback-Leibler regularization loss and can be set as a variable.</p>
</section>
<section id="implementation" class="level3" data-number="2.4">
<h3 data-number="2.4" class="anchored" data-anchor-id="implementation"><span class="header-section-number">2.4</span> Implementation</h3>
<p>I’ve explored two deep learning probabilistic programming languages - Tensorflow Probability(TFP)<span class="citation" data-cites="vaetfp">(<a href="#ref-vaetfp" role="doc-biblioref">Fischer, Alemi, and Dillon n.d.</a>)</span> and Pyro<span class="citation" data-cites="vaepyro">(<a href="#ref-vaepyro" role="doc-biblioref">Tutorials-Pyro n.d.b</a>)</span>. TFP provides ease of implementation and similarity to the structure of a vanilla neural network, an advantage inherent to Keras. However, Pyro in my opinion offers a way to define more complex models with branches, which is an advantage native to PyTorch as well. I’ll explore both for the VAE and use the language which offers the most comfort in implementation for the different variations of VAE.</p>
</section>
<section id="results" class="level3" data-number="2.5">
<h3 data-number="2.5" class="anchored" data-anchor-id="results"><span class="header-section-number">2.5</span> Results</h3>
</section>
</section>
<section id="semi-supervised-vaess-vae" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="semi-supervised-vaess-vae"><span class="header-section-number">3</span> Semi-supervised VAE(SS-VAE)</h2>
<p>So far we’ve ignored labels in the training of VAE. However, the methods proposed by <span class="citation" data-cites="kingma2014semi">(<a href="#ref-kingma2014semi" role="doc-biblioref">Durk P. Kingma et al. 2014</a>)</span>, allow us to create supervised learning models based on the VAE. They propose three variations in the paper to leverage VAEs<span class="citation" data-cites="ssvaepyro">(<a href="#ref-ssvaepyro" role="doc-biblioref">Tutorials-Pyro n.d.a</a>)</span>.</p>
<section id="latent-feature-discriminative-model---m1" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="latent-feature-discriminative-model---m1"><span class="header-section-number">3.1</span> Latent feature discriminative model - M1</h3>
<p>In the section above, we have demonstrated that the latent variable <span class="math inline">\(z\)</span> learns an informative representation of the input space which is well separated. By using samples from posterior <span class="math inline">\(p(z|x)\)</span> as features, we train a classifier. We can use models like k-Nearest Neighbors classifier or SVM to train models even in cases where the number of labeled samples is limited given that we have seen that the latent space meets the various assumptions of semi-supervised learning.</p>
</section>
<section id="generative-semi-supervised-model---m2" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="generative-semi-supervised-model---m2"><span class="header-section-number">3.2</span> Generative semi-supervised model - M2</h3>
<p>This variation on the standard VAE models the data as being generated both by the label <span class="math inline">\(y\)</span> and the latent variable <span class="math inline">\(z\)</span>. The model is described as follows-</p>
<p><span class="math display">\[\begin{align*}
p(y) &amp;= Cat(y|\pi) \\
p(z) &amp;= \mathcal{N}(z|\mathbf{0},I)\\
p_{\theta}(x|y,z) &amp;= f(x;y,z,\theta)
\end{align*}\]</span></p>
<p><span class="math inline">\(Cat(y|\pi)\)</span> is a multinomial distribution. The difference to the VAE is that we consider <span class="math inline">\(y\)</span> as a latent variable in addition to <span class="math inline">\(z\)</span>. The distribution <span class="math inline">\(q_{\phi}(y|x)=Cat(y|\pi_{\phi}(x))\)</span> for the missing labels behaves as a classifier.</p>
<p>The distribution <span class="math inline">\(q_{\phi}(z|x,y)=\mathcal{N}(z|\mu_{\phi}(x,y), \sigma^2_{\phi}(x,y)\)</span>) corresponds to the encoder.</p>
<div id="fig-ssvae" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="figures/ssvae_pgm.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;2: Graphical Model of M2(SS-VAE)<span class="citation" data-cites="9941371">(<a href="#ref-9941371" role="doc-biblioref">Yang et al. 2022</a>)</span></figcaption>
</figure>
</div>
<section id="defining-the-elbo" class="level4" data-number="3.2.1">
<h4 data-number="3.2.1" class="anchored" data-anchor-id="defining-the-elbo"><span class="header-section-number">3.2.1</span> Defining the ELBO</h4>
</section>
</section>
<section id="stacked-generative-semi-supervised-model---m1m2" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="stacked-generative-semi-supervised-model---m1m2"><span class="header-section-number">3.3</span> Stacked generative semi-supervised model - M1+M2</h3>
</section>
</section>
<section id="infinite-vae" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="infinite-vae"><span class="header-section-number">4</span> Infinite VAE</h2>
<p><span class="citation" data-cites="ehsan2017infinite">(<a href="#ref-ehsan2017infinite" role="doc-biblioref">Ehsan Abbasnejad, Dick, and Hengel 2017</a>)</span></p>
<section id="mixture-models" class="level3" data-number="4.1">
<h3 data-number="4.1" class="anchored" data-anchor-id="mixture-models"><span class="header-section-number">4.1</span> Mixture models</h3>
</section>
<section id="dirichlet-process-mixture-models" class="level3" data-number="4.2">
<h3 data-number="4.2" class="anchored" data-anchor-id="dirichlet-process-mixture-models"><span class="header-section-number">4.2</span> Dirichlet Process Mixture Models</h3>
</section>
</section>
<section id="references" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="references"><span class="header-section-number">5</span> References</h2>
<div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-ehsan2017infinite" class="csl-entry" role="listitem">
Ehsan Abbasnejad, M, Anthony Dick, and Anton van den Hengel. 2017. <span>“Infinite Variational Autoencoder for Semi-Supervised Learning.”</span> In <em>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</em>, 5888–97.
</div>
<div id="ref-vaetfp" class="csl-entry" role="listitem">
Fischer, Ian, Alex Alemi, and Joshua V Dillon. n.d. <span>“VAE Using Tensorflow-Probability Layers.”</span> Accessed May 2, 2023. <a href="https://blog.tensorflow.org/2019/03/variational-autoencoders-with.html">https://blog.tensorflow.org/2019/03/variational-autoencoders-with.html</a>.
</div>
<div id="ref-higgins2017beta" class="csl-entry" role="listitem">
Higgins, Irina, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick, Shakir Mohamed, and Alexander Lerchner. 2017. <span>“Beta-Vae: Learning Basic Visual Concepts with a Constrained Variational Framework.”</span> In <em>International Conference on Learning Representations</em>.
</div>
<div id="ref-kingma2014stochastic" class="csl-entry" role="listitem">
Kingma, Diederik P, and Max Welling. 2014. <span>“Stochastic Gradient VB and the Variational Auto-Encoder.”</span> In <em>Second International Conference on Learning Representations, ICLR</em>, 19:121.
</div>
<div id="ref-kingma2014semi" class="csl-entry" role="listitem">
Kingma, Durk P, Shakir Mohamed, Danilo Jimenez Rezende, and Max Welling. 2014. <span>“Semi-Supervised Learning with Deep Generative Models.”</span> <em>Advances in Neural Information Processing Systems</em> 27.
</div>
<div id="ref-ssvaepyro" class="csl-entry" role="listitem">
Tutorials-Pyro. n.d.a. <span>“The Semi-Supervised VAE.”</span> Accessed May 2, 2023. <a href="https://pyro.ai/examples/ss-vae.html">https://pyro.ai/examples/ss-vae.html</a>.
</div>
<div id="ref-vaepyro" class="csl-entry" role="listitem">
———. n.d.b. <span>“VAE Using Pyro.”</span> Accessed May 2, 2023. <a href="https://pyro.ai/examples/vae.html">https://pyro.ai/examples/vae.html</a>.
</div>
<div id="ref-van2020survey" class="csl-entry" role="listitem">
Van Engelen, Jesper E, and Holger H Hoos. 2020. <span>“A Survey on Semi-Supervised Learning.”</span> <em>Machine Learning</em> 109 (2): 373–440.
</div>
<div id="ref-9941371" class="csl-entry" role="listitem">
Yang, Xiangli, Zixing Song, Irwin King, and Zenglin Xu. 2022. <span>“A Survey on Deep Semi-Supervised Learning.”</span> <em>IEEE Transactions on Knowledge and Data Engineering</em>, 1–20. <a href="https://doi.org/10.1109/TKDE.2022.3220219">https://doi.org/10.1109/TKDE.2022.3220219</a>.
</div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>